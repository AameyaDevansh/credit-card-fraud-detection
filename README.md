# ğŸ’³ Credit Card Fraud Detection

A machine learning project to identify fraudulent credit card transactions using a real-world, highly imbalanced dataset. The goal is to build a predictive model that can detect fraud with high accuracy and recall.

---

## ğŸ“‚ Dataset

- **Source**: [Kaggle - Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- **Description**: Anonymized transactions from European credit card holders (September 2013).
- **Size**: 284,807 transactions Ã— 31 features
- **Target**: `Class` â€” 0 (Not Fraud), 1 (Fraud)
- **Imbalance**: Only ~0.17% transactions are fraudulent.

**Note:** To download the dataset, run:
```bash
python get_data.py
```
---

## âš™ï¸ Project Structure

```
credit-card-fraud-detection/
â”œâ”€â”€ data/                        # Dataset CSV
â”œâ”€â”€ models/                     # Saved ML model (.pkl)
â”œâ”€â”€ notebooks/                  # EDA & Model Training notebooks
â”œâ”€â”€ src/                        # Preprocessing Python scripts
â”œâ”€â”€ requirements.txt            # Project dependencies
â”œâ”€â”€ README.md                   # This file
â””â”€â”€ .gitignore
```

---

## ğŸš€ Workflow

### ğŸ” 1. EDA (`EDA_With_Text.ipynb`)
- Checked class imbalance
- Analyzed distributions of `Amount` and `Time`
- Visualized feature correlations
- Compared PCA components for fraud vs non-fraud

### ğŸ§¹ 2. Preprocessing (`src/preprocessing.py`)
- Scaled `Amount` and `Time` features
- Dropped original unscaled columns
- Performed train-test split (stratified)

### âš–ï¸ 3. Class Imbalance Handling
- Applied **SMOTE (Synthetic Minority Oversampling Technique)** on training data to balance classes

### ğŸ¤– 4. Model Training (`Model_Training_With_Text.ipynb`)
- Trained **Logistic Regression**
- Trained **Random Forest Classifier**
- Evaluated using:
  - Precision, Recall, F1-Score
  - ROC-AUC
  - Confusion Matrix
  - ROC Curves

### ğŸ’¾ 5. Model Export
- Saved best-performing model (`fraud_detection_rf.pkl`) using `joblib`

---

## ğŸ§  Best Model: Random Forest

| Metric        | Value      |
|---------------|------------|
| Accuracy      | ~99%       |
| Precision     | High       |
| Recall        | High       |
| ROC-AUC       | ~0.98      |

> Random Forest outperformed Logistic Regression, especially in detecting the minority class.

---

## ğŸ“¦ Requirements

Install dependencies:

```bash
pip install -r requirements.txt
```

If you'd prefer a minimal list:

```txt
pandas
numpy
matplotlib
seaborn
scikit-learn
imbalanced-learn
joblib
```

---

## â–¶ï¸ How to Run

```bash
git clone https://github.com/your-username/credit-card-fraud-detection.git
cd credit-card-fraud-detection
```

Open and run these notebooks:
- `notebooks/EDA_With_Text.ipynb`
- `notebooks/Model_Training_With_Text.ipynb`

---

## âœ… Future Work

- Hyperparameter tuning (GridSearchCV, RandomizedSearchCV)
- Streamlit dashboard for real-time predictions
- Deploy model via Flask or FastAPI
- Use SHAP for model interpretability

---

## âœï¸ Author

**Aameya Devansh**  
NIT Jamshedpur | CSE 2nd year Undergrad  
ğŸ“« adevansh123@gmail.com
=======

